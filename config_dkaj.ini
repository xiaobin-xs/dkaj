[DEFAULT]
n_experiment_repeats = 10
simple_data_splitting_val_ratio = 0.2
fix_test_shuffle_train = 1
datasets = ['pbc', 'framingham', 'synthetic', 'seer2010'] #'seer']
ANN_max_n_neighbors = [128]
init_output_dir = out_baselines
output_dir = out_dkaj
compute_bootstrap_CI = 0
bootstrap_n_samples = 200
bootstrap_CI_coverage = 0.95
bootstrap_random_seed = 4049105963
tuna_random_seed = 2306758833
verbose = 0
early_stopping_patience = 10
eval_horizon_quantiles = [0.25, 0.5, 0.75]
ibs_n_horizon_points = 100
ibs_max_horizon_percentile = 0.9
model_selection_metric = avgCtd # avgIBS or avgCtd

[method: survboost]
learning_rate = [0.01, 0.05, 0.1, 0.5]
n_iter = [20, 100, 200]
max_depth = [-1, 4, 8, 16]
n_time_grid_steps = [64, 128]
ipcw_strategy = ['alternating', 'kaplan-meier']
random_seed = 146561020

[method: dkaj]
n_random_times_per_data_point = 5
max_n_epochs = 1000
batch_size = [1024]
n_layers = [2, 4]
n_nodes = [64, 128]
learning_rate = [0.01, 0.001]
alpha = [0, 0.001, 0.01]
sigma = [0.1, 1]
n_durations = [0, 64, 128]
gamma = [0]
beta = [0.25, 0.5]
squared_radius = [0.1]
min_kernel_weight = [1e-2] # corresponding to tau (with transformation) in the paper
random_seed = 4063380196
finetune_summaries = 0
sumtune_learning_rate = [0.01, 0.001, 0.0001]

[method: dkaj10]
n_random_times_per_data_point = 10
max_n_epochs = 1000
batch_size = [1024]
n_layers = [2, 4]
n_nodes = [64, 128]
learning_rate = [0.01, 0.001]
alpha = [0, 0.001, 0.01]
sigma = [0.1, 1]
n_durations = [0, 64, 128]
gamma = [0]
beta = [0.25, 0.5]
squared_radius = [0.1]
min_kernel_weight = [1e-2] # corresponding to tau (with transformation) in the paper
random_seed = 4063380196
finetune_summaries = 1
sumtune_learning_rate = [0.01, 0.001, 0.0001]